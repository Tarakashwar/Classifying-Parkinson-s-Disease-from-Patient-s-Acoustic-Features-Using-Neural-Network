{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtsUAEFnY7M-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed7bb68e-f114-45bd-f381-a2d9efa7bf50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing important files....\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import tree\n",
        "from sklearn.svm import SVC\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "from xgboost import XGBRegressor, plot_tree\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.inspection import permutation_importance\n",
        "from statistics import mean, stdev\n",
        "from sklearn import tree\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "id": "Yu9AmzVEY-MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Dataset/Parkinson disease.csv')\n"
      ],
      "metadata": {
        "id": "FiHEGGlKY-Jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "jiok4zNbY-Es",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "e8df0d77-2b7d-4ebc-d115-4adca81a0751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
              "0    phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
              "1    phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
              "2    phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
              "3    phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
              "4    phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
              "..              ...          ...           ...           ...             ...   \n",
              "190  phon_R01_S50_2      174.188       230.978        94.261         0.00459   \n",
              "191  phon_R01_S50_3      209.516       253.017        89.488         0.00564   \n",
              "192  phon_R01_S50_4      174.688       240.005        74.287         0.01360   \n",
              "193  phon_R01_S50_5      198.764       396.961        74.904         0.00740   \n",
              "194  phon_R01_S50_6      214.289       260.277        77.973         0.00567   \n",
              "\n",
              "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
              "0             0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
              "1             0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
              "2             0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
              "3             0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
              "4             0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
              "..                ...       ...       ...         ...           ...  ...   \n",
              "190           0.00003   0.00263   0.00259     0.00790       0.04087  ...   \n",
              "191           0.00003   0.00331   0.00292     0.00994       0.02751  ...   \n",
              "192           0.00008   0.00624   0.00564     0.01873       0.02308  ...   \n",
              "193           0.00004   0.00370   0.00390     0.01109       0.02296  ...   \n",
              "194           0.00003   0.00295   0.00317     0.00885       0.01884  ...   \n",
              "\n",
              "     Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
              "0        0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
              "1        0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
              "2        0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
              "3        0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
              "4        0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
              "..           ...      ...     ...     ...       ...       ...       ...   \n",
              "190      0.07008  0.02764  19.517       0  0.448439  0.657899 -6.538586   \n",
              "191      0.04812  0.01810  19.147       0  0.431674  0.683244 -6.195325   \n",
              "192      0.03804  0.10715  17.883       0  0.407567  0.655683 -6.787197   \n",
              "193      0.03794  0.07223  19.020       0  0.451221  0.643956 -6.744577   \n",
              "194      0.03078  0.04398  21.209       0  0.462803  0.664357 -5.724056   \n",
              "\n",
              "      spread2        D2       PPE  \n",
              "0    0.266482  2.301442  0.284654  \n",
              "1    0.335590  2.486855  0.368674  \n",
              "2    0.311173  2.342259  0.332634  \n",
              "3    0.334147  2.405554  0.368975  \n",
              "4    0.234513  2.332180  0.410335  \n",
              "..        ...       ...       ...  \n",
              "190  0.121952  2.657476  0.133050  \n",
              "191  0.129303  2.784312  0.168895  \n",
              "192  0.158453  2.679772  0.131728  \n",
              "193  0.207454  2.138608  0.123306  \n",
              "194  0.190667  2.555477  0.148569  \n",
              "\n",
              "[195 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d4a8cd2-e414-4b96-a6db-14915022ae25\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>MDVP:Fo(Hz)</th>\n",
              "      <th>MDVP:Fhi(Hz)</th>\n",
              "      <th>MDVP:Flo(Hz)</th>\n",
              "      <th>MDVP:Jitter(%)</th>\n",
              "      <th>MDVP:Jitter(Abs)</th>\n",
              "      <th>MDVP:RAP</th>\n",
              "      <th>MDVP:PPQ</th>\n",
              "      <th>Jitter:DDP</th>\n",
              "      <th>MDVP:Shimmer</th>\n",
              "      <th>...</th>\n",
              "      <th>Shimmer:DDA</th>\n",
              "      <th>NHR</th>\n",
              "      <th>HNR</th>\n",
              "      <th>status</th>\n",
              "      <th>RPDE</th>\n",
              "      <th>DFA</th>\n",
              "      <th>spread1</th>\n",
              "      <th>spread2</th>\n",
              "      <th>D2</th>\n",
              "      <th>PPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>phon_R01_S01_1</td>\n",
              "      <td>119.992</td>\n",
              "      <td>157.302</td>\n",
              "      <td>74.997</td>\n",
              "      <td>0.00784</td>\n",
              "      <td>0.00007</td>\n",
              "      <td>0.00370</td>\n",
              "      <td>0.00554</td>\n",
              "      <td>0.01109</td>\n",
              "      <td>0.04374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.06545</td>\n",
              "      <td>0.02211</td>\n",
              "      <td>21.033</td>\n",
              "      <td>1</td>\n",
              "      <td>0.414783</td>\n",
              "      <td>0.815285</td>\n",
              "      <td>-4.813031</td>\n",
              "      <td>0.266482</td>\n",
              "      <td>2.301442</td>\n",
              "      <td>0.284654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>phon_R01_S01_2</td>\n",
              "      <td>122.400</td>\n",
              "      <td>148.650</td>\n",
              "      <td>113.819</td>\n",
              "      <td>0.00968</td>\n",
              "      <td>0.00008</td>\n",
              "      <td>0.00465</td>\n",
              "      <td>0.00696</td>\n",
              "      <td>0.01394</td>\n",
              "      <td>0.06134</td>\n",
              "      <td>...</td>\n",
              "      <td>0.09403</td>\n",
              "      <td>0.01929</td>\n",
              "      <td>19.085</td>\n",
              "      <td>1</td>\n",
              "      <td>0.458359</td>\n",
              "      <td>0.819521</td>\n",
              "      <td>-4.075192</td>\n",
              "      <td>0.335590</td>\n",
              "      <td>2.486855</td>\n",
              "      <td>0.368674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>phon_R01_S01_3</td>\n",
              "      <td>116.682</td>\n",
              "      <td>131.111</td>\n",
              "      <td>111.555</td>\n",
              "      <td>0.01050</td>\n",
              "      <td>0.00009</td>\n",
              "      <td>0.00544</td>\n",
              "      <td>0.00781</td>\n",
              "      <td>0.01633</td>\n",
              "      <td>0.05233</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08270</td>\n",
              "      <td>0.01309</td>\n",
              "      <td>20.651</td>\n",
              "      <td>1</td>\n",
              "      <td>0.429895</td>\n",
              "      <td>0.825288</td>\n",
              "      <td>-4.443179</td>\n",
              "      <td>0.311173</td>\n",
              "      <td>2.342259</td>\n",
              "      <td>0.332634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>phon_R01_S01_4</td>\n",
              "      <td>116.676</td>\n",
              "      <td>137.871</td>\n",
              "      <td>111.366</td>\n",
              "      <td>0.00997</td>\n",
              "      <td>0.00009</td>\n",
              "      <td>0.00502</td>\n",
              "      <td>0.00698</td>\n",
              "      <td>0.01505</td>\n",
              "      <td>0.05492</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08771</td>\n",
              "      <td>0.01353</td>\n",
              "      <td>20.644</td>\n",
              "      <td>1</td>\n",
              "      <td>0.434969</td>\n",
              "      <td>0.819235</td>\n",
              "      <td>-4.117501</td>\n",
              "      <td>0.334147</td>\n",
              "      <td>2.405554</td>\n",
              "      <td>0.368975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>phon_R01_S01_5</td>\n",
              "      <td>116.014</td>\n",
              "      <td>141.781</td>\n",
              "      <td>110.655</td>\n",
              "      <td>0.01284</td>\n",
              "      <td>0.00011</td>\n",
              "      <td>0.00655</td>\n",
              "      <td>0.00908</td>\n",
              "      <td>0.01966</td>\n",
              "      <td>0.06425</td>\n",
              "      <td>...</td>\n",
              "      <td>0.10470</td>\n",
              "      <td>0.01767</td>\n",
              "      <td>19.649</td>\n",
              "      <td>1</td>\n",
              "      <td>0.417356</td>\n",
              "      <td>0.823484</td>\n",
              "      <td>-3.747787</td>\n",
              "      <td>0.234513</td>\n",
              "      <td>2.332180</td>\n",
              "      <td>0.410335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>phon_R01_S50_2</td>\n",
              "      <td>174.188</td>\n",
              "      <td>230.978</td>\n",
              "      <td>94.261</td>\n",
              "      <td>0.00459</td>\n",
              "      <td>0.00003</td>\n",
              "      <td>0.00263</td>\n",
              "      <td>0.00259</td>\n",
              "      <td>0.00790</td>\n",
              "      <td>0.04087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.07008</td>\n",
              "      <td>0.02764</td>\n",
              "      <td>19.517</td>\n",
              "      <td>0</td>\n",
              "      <td>0.448439</td>\n",
              "      <td>0.657899</td>\n",
              "      <td>-6.538586</td>\n",
              "      <td>0.121952</td>\n",
              "      <td>2.657476</td>\n",
              "      <td>0.133050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>phon_R01_S50_3</td>\n",
              "      <td>209.516</td>\n",
              "      <td>253.017</td>\n",
              "      <td>89.488</td>\n",
              "      <td>0.00564</td>\n",
              "      <td>0.00003</td>\n",
              "      <td>0.00331</td>\n",
              "      <td>0.00292</td>\n",
              "      <td>0.00994</td>\n",
              "      <td>0.02751</td>\n",
              "      <td>...</td>\n",
              "      <td>0.04812</td>\n",
              "      <td>0.01810</td>\n",
              "      <td>19.147</td>\n",
              "      <td>0</td>\n",
              "      <td>0.431674</td>\n",
              "      <td>0.683244</td>\n",
              "      <td>-6.195325</td>\n",
              "      <td>0.129303</td>\n",
              "      <td>2.784312</td>\n",
              "      <td>0.168895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>phon_R01_S50_4</td>\n",
              "      <td>174.688</td>\n",
              "      <td>240.005</td>\n",
              "      <td>74.287</td>\n",
              "      <td>0.01360</td>\n",
              "      <td>0.00008</td>\n",
              "      <td>0.00624</td>\n",
              "      <td>0.00564</td>\n",
              "      <td>0.01873</td>\n",
              "      <td>0.02308</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03804</td>\n",
              "      <td>0.10715</td>\n",
              "      <td>17.883</td>\n",
              "      <td>0</td>\n",
              "      <td>0.407567</td>\n",
              "      <td>0.655683</td>\n",
              "      <td>-6.787197</td>\n",
              "      <td>0.158453</td>\n",
              "      <td>2.679772</td>\n",
              "      <td>0.131728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>phon_R01_S50_5</td>\n",
              "      <td>198.764</td>\n",
              "      <td>396.961</td>\n",
              "      <td>74.904</td>\n",
              "      <td>0.00740</td>\n",
              "      <td>0.00004</td>\n",
              "      <td>0.00370</td>\n",
              "      <td>0.00390</td>\n",
              "      <td>0.01109</td>\n",
              "      <td>0.02296</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03794</td>\n",
              "      <td>0.07223</td>\n",
              "      <td>19.020</td>\n",
              "      <td>0</td>\n",
              "      <td>0.451221</td>\n",
              "      <td>0.643956</td>\n",
              "      <td>-6.744577</td>\n",
              "      <td>0.207454</td>\n",
              "      <td>2.138608</td>\n",
              "      <td>0.123306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>phon_R01_S50_6</td>\n",
              "      <td>214.289</td>\n",
              "      <td>260.277</td>\n",
              "      <td>77.973</td>\n",
              "      <td>0.00567</td>\n",
              "      <td>0.00003</td>\n",
              "      <td>0.00295</td>\n",
              "      <td>0.00317</td>\n",
              "      <td>0.00885</td>\n",
              "      <td>0.01884</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03078</td>\n",
              "      <td>0.04398</td>\n",
              "      <td>21.209</td>\n",
              "      <td>0</td>\n",
              "      <td>0.462803</td>\n",
              "      <td>0.664357</td>\n",
              "      <td>-5.724056</td>\n",
              "      <td>0.190667</td>\n",
              "      <td>2.555477</td>\n",
              "      <td>0.148569</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>195 rows Ã— 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d4a8cd2-e414-4b96-a6db-14915022ae25')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9d4a8cd2-e414-4b96-a6db-14915022ae25 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9d4a8cd2-e414-4b96-a6db-14915022ae25');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1efbf3bd-cfa4-4681-b883-24362ee4620e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1efbf3bd-cfa4-4681-b883-24362ee4620e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1efbf3bd-cfa4-4681-b883-24362ee4620e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_#Defining features(X) and labels(Y)....\n",
        "X = df.drop(['status','name'],axis =1).values\n",
        "y = df['status'].values\n",
        "\n"
      ],
      "metadata": {
        "id": "m_FgBxxqY-B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking is any nan value available or not\n",
        "np.any(np.isnan(X))"
      ],
      "metadata": {
        "id": "T5wuvw3CY9_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d13ec54e-4681-4c44-cd73-bf7bba83ff9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Missing value handle\n",
        "imputer = SimpleImputer(missing_values = np.NaN, strategy = 'mean')\n",
        "imputer = imputer.fit(X)\n",
        "X = imputer.transform(X)\n",
        "\n",
        "feature_X = pd.DataFrame(X)\n"
      ],
      "metadata": {
        "id": "Wl8SG7y_Y98t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking is any nan value available or not\n",
        "np.any(np.isnan(y))"
      ],
      "metadata": {
        "id": "8flLSQ0HY953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50c3b86c-5bec-4ff8-ab03-a40cec1479d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "\n"
      ],
      "metadata": {
        "id": "frhenWWNZJ7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled.shape"
      ],
      "metadata": {
        "id": "AGrHIN5sZJ4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "000ddacc-3671-4ae6-9059-38c3bca48fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(195, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y == 1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y== 0)))"
      ],
      "metadata": {
        "id": "u36PEP4ibDqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a00f2a14-c501-48bc-ad20-65e60cd762bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before OverSampling, counts of label '1': 147\n",
            "Before OverSampling, counts of label '0': 48 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 2)\n",
        "X_res, y_res = sm.fit_resample(X_scaled, y.ravel())\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_res.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_res == 1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_res == 0)))"
      ],
      "metadata": {
        "id": "n0ycVSpVbJp7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05ac7d7-f708-44ba-d789-f3f02908f307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After OverSampling, the shape of train_X: (294, 22)\n",
            "After OverSampling, the shape of train_y: (294,) \n",
            "\n",
            "After OverSampling, counts of label '1': 147\n",
            "After OverSampling, counts of label '0': 147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_res= pd.DataFrame(X_res)"
      ],
      "metadata": {
        "id": "I_blmXR7FtYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_res"
      ],
      "metadata": {
        "id": "rBTOwRD4GGWN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "3c84872d-36d6-4505-8607-dcac84e877c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6   \\\n",
              "0   -0.829300 -0.436165 -0.952037  0.334914  0.749759  0.132963  0.760800   \n",
              "1   -0.770972 -0.530974 -0.057721  0.715418  1.037674  0.453892  1.276809   \n",
              "2   -0.909476 -0.723168 -0.109875  0.884991  1.325589  0.720770  1.585687   \n",
              "3   -0.909622 -0.649092 -0.114229  0.775389  1.325589  0.578885  1.284076   \n",
              "4   -0.925657 -0.606245 -0.130608  1.368893  1.901418  1.095750  2.047187   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "289  2.121012  0.620643  2.634119 -0.736536 -0.977729 -0.617370 -0.696395   \n",
              "290 -0.755081 -0.733204 -0.034862 -0.400977 -0.401899 -0.697273 -0.688380   \n",
              "291 -0.903416 -0.578781 -0.375684 -0.556310 -0.401899 -0.522953 -0.461817   \n",
              "292 -0.605065 -0.628511  0.057710 -0.280321 -0.132689 -0.565714 -0.591376   \n",
              "293 -0.754753 -0.722923  0.002674 -0.277873 -0.226440 -0.583001 -0.565781   \n",
              "\n",
              "           7         8         9   ...        12        13        14  \\\n",
              "0    0.131755  0.745985  0.739536  ...  0.332985  0.607532 -0.067893   \n",
              "1    0.452684  1.681731  1.768464  ...  1.159454  1.548254 -0.137843   \n",
              "2    0.721813  1.202693  1.027636  ...  0.699187  1.175323 -0.291633   \n",
              "3    0.577677  1.340396  1.207698  ...  0.806859  1.340229 -0.280719   \n",
              "4    1.096793  1.836448  1.552389  ...  1.216839  1.899461 -0.178026   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "289 -0.618064 -0.812995 -0.785095  ... -0.816649 -0.745982 -0.491836   \n",
              "290 -0.696246 -0.679829 -0.654543  ... -0.593430 -0.621674 -0.501644   \n",
              "291 -0.523014 -0.701134 -0.707435  ... -0.646632 -0.680279 -0.470599   \n",
              "292 -0.565793 -0.258378 -0.285119  ... -0.283194 -0.172967 -0.496321   \n",
              "293 -0.583521 -0.603391 -0.607889  ... -0.518671 -0.553296 -0.443094   \n",
              "\n",
              "           15        16        17        18        19        20        21  \n",
              "0   -0.193225 -0.807838  1.760814  0.801323  0.480477 -0.210531  0.868886  \n",
              "1   -0.634508 -0.387524  1.837562  1.479853  1.311185  0.275077  1.803605  \n",
              "2   -0.279760 -0.662075  1.942048  1.141445  1.017682 -0.103629  1.402661  \n",
              "3   -0.281346 -0.613134  1.832380  1.440945  1.293840  0.062145  1.806954  \n",
              "4   -0.506745 -0.783021  1.909364  1.780940  0.096195 -0.130026  2.267082  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "289  0.623186 -0.661366 -1.606899 -1.295742 -0.922739 -0.614970 -1.243979  \n",
              "290  0.697700  0.373384  0.655791 -0.743496  0.452486 -0.861429 -0.866127  \n",
              "291  0.809847 -1.067160  0.695486 -0.306391  0.031492 -1.319266 -0.483689  \n",
              "292  0.791760 -0.729145  1.202083 -1.073856  0.482553 -0.456870 -0.677416  \n",
              "293  0.463630  0.682185  0.581072 -0.770127  0.423553 -1.035935 -0.940301  \n",
              "\n",
              "[294 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36441b2d-5c73-4030-bfb0-4b9aa8a6ca6c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.829300</td>\n",
              "      <td>-0.436165</td>\n",
              "      <td>-0.952037</td>\n",
              "      <td>0.334914</td>\n",
              "      <td>0.749759</td>\n",
              "      <td>0.132963</td>\n",
              "      <td>0.760800</td>\n",
              "      <td>0.131755</td>\n",
              "      <td>0.745985</td>\n",
              "      <td>0.739536</td>\n",
              "      <td>...</td>\n",
              "      <td>0.332985</td>\n",
              "      <td>0.607532</td>\n",
              "      <td>-0.067893</td>\n",
              "      <td>-0.193225</td>\n",
              "      <td>-0.807838</td>\n",
              "      <td>1.760814</td>\n",
              "      <td>0.801323</td>\n",
              "      <td>0.480477</td>\n",
              "      <td>-0.210531</td>\n",
              "      <td>0.868886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.770972</td>\n",
              "      <td>-0.530974</td>\n",
              "      <td>-0.057721</td>\n",
              "      <td>0.715418</td>\n",
              "      <td>1.037674</td>\n",
              "      <td>0.453892</td>\n",
              "      <td>1.276809</td>\n",
              "      <td>0.452684</td>\n",
              "      <td>1.681731</td>\n",
              "      <td>1.768464</td>\n",
              "      <td>...</td>\n",
              "      <td>1.159454</td>\n",
              "      <td>1.548254</td>\n",
              "      <td>-0.137843</td>\n",
              "      <td>-0.634508</td>\n",
              "      <td>-0.387524</td>\n",
              "      <td>1.837562</td>\n",
              "      <td>1.479853</td>\n",
              "      <td>1.311185</td>\n",
              "      <td>0.275077</td>\n",
              "      <td>1.803605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.909476</td>\n",
              "      <td>-0.723168</td>\n",
              "      <td>-0.109875</td>\n",
              "      <td>0.884991</td>\n",
              "      <td>1.325589</td>\n",
              "      <td>0.720770</td>\n",
              "      <td>1.585687</td>\n",
              "      <td>0.721813</td>\n",
              "      <td>1.202693</td>\n",
              "      <td>1.027636</td>\n",
              "      <td>...</td>\n",
              "      <td>0.699187</td>\n",
              "      <td>1.175323</td>\n",
              "      <td>-0.291633</td>\n",
              "      <td>-0.279760</td>\n",
              "      <td>-0.662075</td>\n",
              "      <td>1.942048</td>\n",
              "      <td>1.141445</td>\n",
              "      <td>1.017682</td>\n",
              "      <td>-0.103629</td>\n",
              "      <td>1.402661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.909622</td>\n",
              "      <td>-0.649092</td>\n",
              "      <td>-0.114229</td>\n",
              "      <td>0.775389</td>\n",
              "      <td>1.325589</td>\n",
              "      <td>0.578885</td>\n",
              "      <td>1.284076</td>\n",
              "      <td>0.577677</td>\n",
              "      <td>1.340396</td>\n",
              "      <td>1.207698</td>\n",
              "      <td>...</td>\n",
              "      <td>0.806859</td>\n",
              "      <td>1.340229</td>\n",
              "      <td>-0.280719</td>\n",
              "      <td>-0.281346</td>\n",
              "      <td>-0.613134</td>\n",
              "      <td>1.832380</td>\n",
              "      <td>1.440945</td>\n",
              "      <td>1.293840</td>\n",
              "      <td>0.062145</td>\n",
              "      <td>1.806954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.925657</td>\n",
              "      <td>-0.606245</td>\n",
              "      <td>-0.130608</td>\n",
              "      <td>1.368893</td>\n",
              "      <td>1.901418</td>\n",
              "      <td>1.095750</td>\n",
              "      <td>2.047187</td>\n",
              "      <td>1.096793</td>\n",
              "      <td>1.836448</td>\n",
              "      <td>1.552389</td>\n",
              "      <td>...</td>\n",
              "      <td>1.216839</td>\n",
              "      <td>1.899461</td>\n",
              "      <td>-0.178026</td>\n",
              "      <td>-0.506745</td>\n",
              "      <td>-0.783021</td>\n",
              "      <td>1.909364</td>\n",
              "      <td>1.780940</td>\n",
              "      <td>0.096195</td>\n",
              "      <td>-0.130026</td>\n",
              "      <td>2.267082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>2.121012</td>\n",
              "      <td>0.620643</td>\n",
              "      <td>2.634119</td>\n",
              "      <td>-0.736536</td>\n",
              "      <td>-0.977729</td>\n",
              "      <td>-0.617370</td>\n",
              "      <td>-0.696395</td>\n",
              "      <td>-0.618064</td>\n",
              "      <td>-0.812995</td>\n",
              "      <td>-0.785095</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.816649</td>\n",
              "      <td>-0.745982</td>\n",
              "      <td>-0.491836</td>\n",
              "      <td>0.623186</td>\n",
              "      <td>-0.661366</td>\n",
              "      <td>-1.606899</td>\n",
              "      <td>-1.295742</td>\n",
              "      <td>-0.922739</td>\n",
              "      <td>-0.614970</td>\n",
              "      <td>-1.243979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>-0.755081</td>\n",
              "      <td>-0.733204</td>\n",
              "      <td>-0.034862</td>\n",
              "      <td>-0.400977</td>\n",
              "      <td>-0.401899</td>\n",
              "      <td>-0.697273</td>\n",
              "      <td>-0.688380</td>\n",
              "      <td>-0.696246</td>\n",
              "      <td>-0.679829</td>\n",
              "      <td>-0.654543</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.593430</td>\n",
              "      <td>-0.621674</td>\n",
              "      <td>-0.501644</td>\n",
              "      <td>0.697700</td>\n",
              "      <td>0.373384</td>\n",
              "      <td>0.655791</td>\n",
              "      <td>-0.743496</td>\n",
              "      <td>0.452486</td>\n",
              "      <td>-0.861429</td>\n",
              "      <td>-0.866127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>-0.903416</td>\n",
              "      <td>-0.578781</td>\n",
              "      <td>-0.375684</td>\n",
              "      <td>-0.556310</td>\n",
              "      <td>-0.401899</td>\n",
              "      <td>-0.522953</td>\n",
              "      <td>-0.461817</td>\n",
              "      <td>-0.523014</td>\n",
              "      <td>-0.701134</td>\n",
              "      <td>-0.707435</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.646632</td>\n",
              "      <td>-0.680279</td>\n",
              "      <td>-0.470599</td>\n",
              "      <td>0.809847</td>\n",
              "      <td>-1.067160</td>\n",
              "      <td>0.695486</td>\n",
              "      <td>-0.306391</td>\n",
              "      <td>0.031492</td>\n",
              "      <td>-1.319266</td>\n",
              "      <td>-0.483689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>-0.605065</td>\n",
              "      <td>-0.628511</td>\n",
              "      <td>0.057710</td>\n",
              "      <td>-0.280321</td>\n",
              "      <td>-0.132689</td>\n",
              "      <td>-0.565714</td>\n",
              "      <td>-0.591376</td>\n",
              "      <td>-0.565793</td>\n",
              "      <td>-0.258378</td>\n",
              "      <td>-0.285119</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.283194</td>\n",
              "      <td>-0.172967</td>\n",
              "      <td>-0.496321</td>\n",
              "      <td>0.791760</td>\n",
              "      <td>-0.729145</td>\n",
              "      <td>1.202083</td>\n",
              "      <td>-1.073856</td>\n",
              "      <td>0.482553</td>\n",
              "      <td>-0.456870</td>\n",
              "      <td>-0.677416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>-0.754753</td>\n",
              "      <td>-0.722923</td>\n",
              "      <td>0.002674</td>\n",
              "      <td>-0.277873</td>\n",
              "      <td>-0.226440</td>\n",
              "      <td>-0.583001</td>\n",
              "      <td>-0.565781</td>\n",
              "      <td>-0.583521</td>\n",
              "      <td>-0.603391</td>\n",
              "      <td>-0.607889</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.518671</td>\n",
              "      <td>-0.553296</td>\n",
              "      <td>-0.443094</td>\n",
              "      <td>0.463630</td>\n",
              "      <td>0.682185</td>\n",
              "      <td>0.581072</td>\n",
              "      <td>-0.770127</td>\n",
              "      <td>0.423553</td>\n",
              "      <td>-1.035935</td>\n",
              "      <td>-0.940301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>294 rows Ã— 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36441b2d-5c73-4030-bfb0-4b9aa8a6ca6c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36441b2d-5c73-4030-bfb0-4b9aa8a6ca6c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36441b2d-5c73-4030-bfb0-4b9aa8a6ca6c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b26d29a1-a762-4170-a455-2c6efee430e6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b26d29a1-a762-4170-a455-2c6efee430e6')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b26d29a1-a762-4170-a455-2c6efee430e6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_res.duplicated())"
      ],
      "metadata": {
        "id": "eDF6l8vzGfKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af8ef9ae-87be-4305-ee00-a4aa14edbd30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      False\n",
            "1      False\n",
            "2      False\n",
            "3      False\n",
            "4      False\n",
            "       ...  \n",
            "289    False\n",
            "290    False\n",
            "291    False\n",
            "292    False\n",
            "293    False\n",
            "Length: 294, dtype: bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train and test data set split.....\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "_QIV_i6aZJtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name= \"ANN(Normal)\"\n",
        "#Definimng model\n",
        "model = Sequential()\n",
        "model.add(Dense(30,input_dim=22,activation='sigmoid'))\n",
        "model.add(Dense(40,activation='sigmoid'))\n",
        "model.add(Dense(10,activation='sigmoid'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "-pNJJFbMZUVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam',loss='mse',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XVaWP4oWc4ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the defined model\n",
        "model.fit(X_res, y_res,validation_data=(X_test,y_test),batch_size=32,epochs=500)"
      ],
      "metadata": {
        "id": "R5jVV58zZUSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "712d3965-cf48-4cc8-84ab-669763b7ab0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "10/10 [==============================] - 1s 31ms/step - loss: 0.2497 - accuracy: 0.5000 - val_loss: 0.2482 - val_accuracy: 0.4576\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2461 - accuracy: 0.6395 - val_loss: 0.2430 - val_accuracy: 0.5932\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2440 - accuracy: 0.5374 - val_loss: 0.2400 - val_accuracy: 0.5932\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2401 - accuracy: 0.6395 - val_loss: 0.2373 - val_accuracy: 0.7458\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2363 - accuracy: 0.7721 - val_loss: 0.2337 - val_accuracy: 0.8305\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2316 - accuracy: 0.7789 - val_loss: 0.2292 - val_accuracy: 0.7797\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2258 - accuracy: 0.7653 - val_loss: 0.2235 - val_accuracy: 0.7797\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2194 - accuracy: 0.7721 - val_loss: 0.2158 - val_accuracy: 0.8136\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2115 - accuracy: 0.7925 - val_loss: 0.2069 - val_accuracy: 0.8136\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2036 - accuracy: 0.7857 - val_loss: 0.1979 - val_accuracy: 0.7966\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1952 - accuracy: 0.7823 - val_loss: 0.1894 - val_accuracy: 0.7966\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1864 - accuracy: 0.7823 - val_loss: 0.1816 - val_accuracy: 0.8136\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1788 - accuracy: 0.7925 - val_loss: 0.1747 - val_accuracy: 0.8136\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1721 - accuracy: 0.7925 - val_loss: 0.1678 - val_accuracy: 0.8305\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1659 - accuracy: 0.7925 - val_loss: 0.1626 - val_accuracy: 0.8136\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1611 - accuracy: 0.7959 - val_loss: 0.1578 - val_accuracy: 0.8136\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1564 - accuracy: 0.7925 - val_loss: 0.1550 - val_accuracy: 0.8305\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1536 - accuracy: 0.7959 - val_loss: 0.1511 - val_accuracy: 0.8305\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1499 - accuracy: 0.8095 - val_loss: 0.1485 - val_accuracy: 0.8305\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1469 - accuracy: 0.8163 - val_loss: 0.1455 - val_accuracy: 0.8305\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1442 - accuracy: 0.8163 - val_loss: 0.1432 - val_accuracy: 0.8136\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1421 - accuracy: 0.8231 - val_loss: 0.1413 - val_accuracy: 0.8305\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1394 - accuracy: 0.8231 - val_loss: 0.1393 - val_accuracy: 0.8136\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1380 - accuracy: 0.8299 - val_loss: 0.1377 - val_accuracy: 0.8136\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1362 - accuracy: 0.8333 - val_loss: 0.1367 - val_accuracy: 0.8305\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1340 - accuracy: 0.8333 - val_loss: 0.1357 - val_accuracy: 0.8305\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1322 - accuracy: 0.8333 - val_loss: 0.1345 - val_accuracy: 0.8305\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1315 - accuracy: 0.8367 - val_loss: 0.1343 - val_accuracy: 0.8305\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1301 - accuracy: 0.8367 - val_loss: 0.1326 - val_accuracy: 0.8305\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1278 - accuracy: 0.8401 - val_loss: 0.1328 - val_accuracy: 0.8136\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1269 - accuracy: 0.8435 - val_loss: 0.1320 - val_accuracy: 0.8305\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1256 - accuracy: 0.8537 - val_loss: 0.1304 - val_accuracy: 0.8475\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1242 - accuracy: 0.8503 - val_loss: 0.1292 - val_accuracy: 0.8475\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1230 - accuracy: 0.8435 - val_loss: 0.1282 - val_accuracy: 0.8136\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1222 - accuracy: 0.8503 - val_loss: 0.1276 - val_accuracy: 0.8305\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1205 - accuracy: 0.8469 - val_loss: 0.1271 - val_accuracy: 0.8305\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1207 - accuracy: 0.8537 - val_loss: 0.1274 - val_accuracy: 0.8475\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1195 - accuracy: 0.8503 - val_loss: 0.1262 - val_accuracy: 0.8305\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1183 - accuracy: 0.8469 - val_loss: 0.1258 - val_accuracy: 0.8305\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1173 - accuracy: 0.8469 - val_loss: 0.1255 - val_accuracy: 0.8305\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1167 - accuracy: 0.8469 - val_loss: 0.1255 - val_accuracy: 0.8305\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1160 - accuracy: 0.8537 - val_loss: 0.1248 - val_accuracy: 0.8305\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1151 - accuracy: 0.8469 - val_loss: 0.1242 - val_accuracy: 0.8305\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1144 - accuracy: 0.8469 - val_loss: 0.1239 - val_accuracy: 0.8305\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1142 - accuracy: 0.8469 - val_loss: 0.1233 - val_accuracy: 0.8305\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1139 - accuracy: 0.8469 - val_loss: 0.1229 - val_accuracy: 0.8305\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1130 - accuracy: 0.8537 - val_loss: 0.1223 - val_accuracy: 0.8305\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1122 - accuracy: 0.8571 - val_loss: 0.1221 - val_accuracy: 0.8305\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1117 - accuracy: 0.8571 - val_loss: 0.1214 - val_accuracy: 0.8305\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1112 - accuracy: 0.8537 - val_loss: 0.1208 - val_accuracy: 0.8305\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1105 - accuracy: 0.8537 - val_loss: 0.1204 - val_accuracy: 0.8305\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1101 - accuracy: 0.8503 - val_loss: 0.1205 - val_accuracy: 0.8305\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1095 - accuracy: 0.8503 - val_loss: 0.1200 - val_accuracy: 0.8305\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1086 - accuracy: 0.8571 - val_loss: 0.1194 - val_accuracy: 0.8305\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1078 - accuracy: 0.8537 - val_loss: 0.1188 - val_accuracy: 0.8305\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1084 - accuracy: 0.8571 - val_loss: 0.1188 - val_accuracy: 0.8305\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1065 - accuracy: 0.8605 - val_loss: 0.1177 - val_accuracy: 0.8475\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1063 - accuracy: 0.8741 - val_loss: 0.1171 - val_accuracy: 0.8644\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1060 - accuracy: 0.8741 - val_loss: 0.1166 - val_accuracy: 0.8475\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1052 - accuracy: 0.8707 - val_loss: 0.1159 - val_accuracy: 0.8475\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1042 - accuracy: 0.8707 - val_loss: 0.1155 - val_accuracy: 0.8475\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1036 - accuracy: 0.8707 - val_loss: 0.1151 - val_accuracy: 0.8475\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1033 - accuracy: 0.8673 - val_loss: 0.1143 - val_accuracy: 0.8475\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1024 - accuracy: 0.8707 - val_loss: 0.1136 - val_accuracy: 0.8475\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1022 - accuracy: 0.8810 - val_loss: 0.1136 - val_accuracy: 0.8644\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1027 - accuracy: 0.8810 - val_loss: 0.1143 - val_accuracy: 0.8644\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1021 - accuracy: 0.8776 - val_loss: 0.1141 - val_accuracy: 0.8475\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1011 - accuracy: 0.8707 - val_loss: 0.1141 - val_accuracy: 0.8475\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1004 - accuracy: 0.8741 - val_loss: 0.1139 - val_accuracy: 0.8475\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1000 - accuracy: 0.8707 - val_loss: 0.1139 - val_accuracy: 0.8475\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0997 - accuracy: 0.8707 - val_loss: 0.1137 - val_accuracy: 0.8475\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0994 - accuracy: 0.8741 - val_loss: 0.1134 - val_accuracy: 0.8475\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0986 - accuracy: 0.8673 - val_loss: 0.1130 - val_accuracy: 0.8475\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0983 - accuracy: 0.8741 - val_loss: 0.1129 - val_accuracy: 0.8475\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0986 - accuracy: 0.8741 - val_loss: 0.1118 - val_accuracy: 0.8475\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0975 - accuracy: 0.8707 - val_loss: 0.1115 - val_accuracy: 0.8475\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0973 - accuracy: 0.8741 - val_loss: 0.1118 - val_accuracy: 0.8475\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0972 - accuracy: 0.8810 - val_loss: 0.1112 - val_accuracy: 0.8475\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0970 - accuracy: 0.8707 - val_loss: 0.1103 - val_accuracy: 0.8475\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0963 - accuracy: 0.8741 - val_loss: 0.1099 - val_accuracy: 0.8475\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0959 - accuracy: 0.8810 - val_loss: 0.1097 - val_accuracy: 0.8475\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0956 - accuracy: 0.8776 - val_loss: 0.1090 - val_accuracy: 0.8644\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0952 - accuracy: 0.8776 - val_loss: 0.1087 - val_accuracy: 0.8644\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0949 - accuracy: 0.8810 - val_loss: 0.1081 - val_accuracy: 0.8644\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0955 - accuracy: 0.8878 - val_loss: 0.1081 - val_accuracy: 0.8644\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0950 - accuracy: 0.8878 - val_loss: 0.1073 - val_accuracy: 0.8644\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0941 - accuracy: 0.8810 - val_loss: 0.1073 - val_accuracy: 0.8644\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0934 - accuracy: 0.8741 - val_loss: 0.1069 - val_accuracy: 0.8644\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0931 - accuracy: 0.8810 - val_loss: 0.1060 - val_accuracy: 0.8644\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0931 - accuracy: 0.8844 - val_loss: 0.1054 - val_accuracy: 0.8644\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0932 - accuracy: 0.8844 - val_loss: 0.1047 - val_accuracy: 0.8644\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0925 - accuracy: 0.8878 - val_loss: 0.1048 - val_accuracy: 0.8814\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0918 - accuracy: 0.8912 - val_loss: 0.1046 - val_accuracy: 0.8814\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0917 - accuracy: 0.8844 - val_loss: 0.1048 - val_accuracy: 0.8814\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0912 - accuracy: 0.8912 - val_loss: 0.1042 - val_accuracy: 0.8814\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0908 - accuracy: 0.8912 - val_loss: 0.1039 - val_accuracy: 0.8814\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0908 - accuracy: 0.8878 - val_loss: 0.1046 - val_accuracy: 0.8644\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0903 - accuracy: 0.8878 - val_loss: 0.1043 - val_accuracy: 0.8644\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0916 - accuracy: 0.8912 - val_loss: 0.1036 - val_accuracy: 0.8644\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0891 - accuracy: 0.8844 - val_loss: 0.1044 - val_accuracy: 0.8475\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0904 - accuracy: 0.8810 - val_loss: 0.1069 - val_accuracy: 0.8644\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0900 - accuracy: 0.8912 - val_loss: 0.1059 - val_accuracy: 0.8644\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0887 - accuracy: 0.8912 - val_loss: 0.1043 - val_accuracy: 0.8644\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0894 - accuracy: 0.8912 - val_loss: 0.1045 - val_accuracy: 0.8644\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0886 - accuracy: 0.8946 - val_loss: 0.1037 - val_accuracy: 0.8644\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0877 - accuracy: 0.8912 - val_loss: 0.1040 - val_accuracy: 0.8644\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0874 - accuracy: 0.8946 - val_loss: 0.1038 - val_accuracy: 0.8644\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0872 - accuracy: 0.8912 - val_loss: 0.1030 - val_accuracy: 0.8644\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0872 - accuracy: 0.8912 - val_loss: 0.1024 - val_accuracy: 0.8644\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0865 - accuracy: 0.8912 - val_loss: 0.1025 - val_accuracy: 0.8814\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0862 - accuracy: 0.8946 - val_loss: 0.1025 - val_accuracy: 0.8814\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0858 - accuracy: 0.8980 - val_loss: 0.1026 - val_accuracy: 0.8814\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0858 - accuracy: 0.8980 - val_loss: 0.1022 - val_accuracy: 0.8814\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0853 - accuracy: 0.8946 - val_loss: 0.1013 - val_accuracy: 0.8644\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0852 - accuracy: 0.8946 - val_loss: 0.1013 - val_accuracy: 0.8814\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0849 - accuracy: 0.8946 - val_loss: 0.1014 - val_accuracy: 0.8814\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0841 - accuracy: 0.8980 - val_loss: 0.0997 - val_accuracy: 0.8814\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0841 - accuracy: 0.9014 - val_loss: 0.0999 - val_accuracy: 0.8814\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0841 - accuracy: 0.9014 - val_loss: 0.1015 - val_accuracy: 0.8644\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0843 - accuracy: 0.8946 - val_loss: 0.0992 - val_accuracy: 0.8814\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0848 - accuracy: 0.8980 - val_loss: 0.1011 - val_accuracy: 0.8644\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9014 - val_loss: 0.0993 - val_accuracy: 0.8814\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0823 - accuracy: 0.8946 - val_loss: 0.0992 - val_accuracy: 0.8644\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0820 - accuracy: 0.8980 - val_loss: 0.0998 - val_accuracy: 0.8644\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0816 - accuracy: 0.9048 - val_loss: 0.1011 - val_accuracy: 0.8644\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9014 - val_loss: 0.1010 - val_accuracy: 0.8644\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0811 - accuracy: 0.9048 - val_loss: 0.0999 - val_accuracy: 0.8814\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9082 - val_loss: 0.0991 - val_accuracy: 0.8814\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0805 - accuracy: 0.9014 - val_loss: 0.1014 - val_accuracy: 0.8644\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0806 - accuracy: 0.9082 - val_loss: 0.0991 - val_accuracy: 0.8644\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0799 - accuracy: 0.9048 - val_loss: 0.0991 - val_accuracy: 0.8644\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0795 - accuracy: 0.9014 - val_loss: 0.0993 - val_accuracy: 0.8475\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0791 - accuracy: 0.9048 - val_loss: 0.0981 - val_accuracy: 0.8644\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0789 - accuracy: 0.9082 - val_loss: 0.0978 - val_accuracy: 0.8644\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9048 - val_loss: 0.0995 - val_accuracy: 0.8644\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9048 - val_loss: 0.0983 - val_accuracy: 0.8644\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0777 - accuracy: 0.9048 - val_loss: 0.0970 - val_accuracy: 0.8644\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0772 - accuracy: 0.9082 - val_loss: 0.0975 - val_accuracy: 0.8814\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0772 - accuracy: 0.9048 - val_loss: 0.0984 - val_accuracy: 0.8644\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0770 - accuracy: 0.9082 - val_loss: 0.0968 - val_accuracy: 0.8814\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0764 - accuracy: 0.9116 - val_loss: 0.0971 - val_accuracy: 0.8644\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9116 - val_loss: 0.0950 - val_accuracy: 0.8814\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0754 - accuracy: 0.9150 - val_loss: 0.0956 - val_accuracy: 0.8814\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0752 - accuracy: 0.9116 - val_loss: 0.0956 - val_accuracy: 0.8814\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0750 - accuracy: 0.9082 - val_loss: 0.0951 - val_accuracy: 0.8814\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0747 - accuracy: 0.9184 - val_loss: 0.0931 - val_accuracy: 0.8983\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0742 - accuracy: 0.9150 - val_loss: 0.0945 - val_accuracy: 0.8814\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0740 - accuracy: 0.9116 - val_loss: 0.0950 - val_accuracy: 0.8644\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0737 - accuracy: 0.9116 - val_loss: 0.0943 - val_accuracy: 0.8644\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0734 - accuracy: 0.9150 - val_loss: 0.0929 - val_accuracy: 0.8814\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0739 - accuracy: 0.9184 - val_loss: 0.0926 - val_accuracy: 0.8814\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0730 - accuracy: 0.9082 - val_loss: 0.0959 - val_accuracy: 0.8644\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0726 - accuracy: 0.9082 - val_loss: 0.0938 - val_accuracy: 0.8644\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0720 - accuracy: 0.9184 - val_loss: 0.0916 - val_accuracy: 0.8983\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0714 - accuracy: 0.9184 - val_loss: 0.0913 - val_accuracy: 0.8983\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0719 - accuracy: 0.9218 - val_loss: 0.0901 - val_accuracy: 0.8983\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0703 - accuracy: 0.9218 - val_loss: 0.0919 - val_accuracy: 0.8644\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.9150 - val_loss: 0.0956 - val_accuracy: 0.8644\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0717 - accuracy: 0.9116 - val_loss: 0.0955 - val_accuracy: 0.8644\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9116 - val_loss: 0.0910 - val_accuracy: 0.8814\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0697 - accuracy: 0.9218 - val_loss: 0.0904 - val_accuracy: 0.8814\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.9150 - val_loss: 0.0917 - val_accuracy: 0.8644\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0686 - accuracy: 0.9150 - val_loss: 0.0923 - val_accuracy: 0.8644\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0688 - accuracy: 0.9218 - val_loss: 0.0889 - val_accuracy: 0.8983\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0684 - accuracy: 0.9252 - val_loss: 0.0901 - val_accuracy: 0.8814\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0674 - accuracy: 0.9252 - val_loss: 0.0873 - val_accuracy: 0.8983\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0676 - accuracy: 0.9184 - val_loss: 0.0907 - val_accuracy: 0.8644\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0673 - accuracy: 0.9184 - val_loss: 0.0901 - val_accuracy: 0.8644\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0664 - accuracy: 0.9218 - val_loss: 0.0855 - val_accuracy: 0.8983\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0665 - accuracy: 0.9218 - val_loss: 0.0881 - val_accuracy: 0.8644\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0654 - accuracy: 0.9252 - val_loss: 0.0858 - val_accuracy: 0.8983\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0654 - accuracy: 0.9252 - val_loss: 0.0861 - val_accuracy: 0.8983\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0650 - accuracy: 0.9252 - val_loss: 0.0844 - val_accuracy: 0.8983\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0645 - accuracy: 0.9252 - val_loss: 0.0850 - val_accuracy: 0.8983\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0643 - accuracy: 0.9252 - val_loss: 0.0836 - val_accuracy: 0.9153\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0640 - accuracy: 0.9286 - val_loss: 0.0839 - val_accuracy: 0.9153\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0637 - accuracy: 0.9218 - val_loss: 0.0859 - val_accuracy: 0.8644\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0633 - accuracy: 0.9218 - val_loss: 0.0848 - val_accuracy: 0.8814\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0633 - accuracy: 0.9218 - val_loss: 0.0810 - val_accuracy: 0.9153\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0625 - accuracy: 0.9252 - val_loss: 0.0821 - val_accuracy: 0.8983\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0626 - accuracy: 0.9252 - val_loss: 0.0845 - val_accuracy: 0.8814\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0617 - accuracy: 0.9252 - val_loss: 0.0821 - val_accuracy: 0.8814\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0618 - accuracy: 0.9252 - val_loss: 0.0798 - val_accuracy: 0.9153\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0607 - accuracy: 0.9252 - val_loss: 0.0831 - val_accuracy: 0.8814\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0607 - accuracy: 0.9286 - val_loss: 0.0805 - val_accuracy: 0.9153\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0602 - accuracy: 0.9320 - val_loss: 0.0797 - val_accuracy: 0.9153\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0598 - accuracy: 0.9354 - val_loss: 0.0810 - val_accuracy: 0.8983\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0597 - accuracy: 0.9286 - val_loss: 0.0800 - val_accuracy: 0.8983\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0590 - accuracy: 0.9320 - val_loss: 0.0786 - val_accuracy: 0.9153\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0588 - accuracy: 0.9354 - val_loss: 0.0778 - val_accuracy: 0.9322\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0580 - accuracy: 0.9388 - val_loss: 0.0799 - val_accuracy: 0.8983\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0585 - accuracy: 0.9354 - val_loss: 0.0802 - val_accuracy: 0.8814\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0585 - accuracy: 0.9320 - val_loss: 0.0796 - val_accuracy: 0.8983\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0575 - accuracy: 0.9320 - val_loss: 0.0764 - val_accuracy: 0.9153\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0572 - accuracy: 0.9354 - val_loss: 0.0771 - val_accuracy: 0.9153\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0565 - accuracy: 0.9388 - val_loss: 0.0769 - val_accuracy: 0.9153\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0562 - accuracy: 0.9354 - val_loss: 0.0752 - val_accuracy: 0.9322\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0557 - accuracy: 0.9422 - val_loss: 0.0756 - val_accuracy: 0.9322\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0558 - accuracy: 0.9388 - val_loss: 0.0767 - val_accuracy: 0.9153\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0553 - accuracy: 0.9388 - val_loss: 0.0766 - val_accuracy: 0.9153\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0553 - accuracy: 0.9422 - val_loss: 0.0738 - val_accuracy: 0.9322\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0544 - accuracy: 0.9422 - val_loss: 0.0733 - val_accuracy: 0.9322\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0546 - accuracy: 0.9388 - val_loss: 0.0726 - val_accuracy: 0.9322\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0538 - accuracy: 0.9354 - val_loss: 0.0755 - val_accuracy: 0.9153\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0537 - accuracy: 0.9422 - val_loss: 0.0740 - val_accuracy: 0.9153\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0529 - accuracy: 0.9456 - val_loss: 0.0725 - val_accuracy: 0.9322\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0542 - accuracy: 0.9388 - val_loss: 0.0714 - val_accuracy: 0.9322\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0524 - accuracy: 0.9456 - val_loss: 0.0744 - val_accuracy: 0.9153\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0519 - accuracy: 0.9388 - val_loss: 0.0727 - val_accuracy: 0.9153\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0514 - accuracy: 0.9388 - val_loss: 0.0733 - val_accuracy: 0.9153\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0515 - accuracy: 0.9388 - val_loss: 0.0718 - val_accuracy: 0.9153\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0506 - accuracy: 0.9422 - val_loss: 0.0712 - val_accuracy: 0.9153\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0504 - accuracy: 0.9456 - val_loss: 0.0701 - val_accuracy: 0.9322\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0502 - accuracy: 0.9422 - val_loss: 0.0695 - val_accuracy: 0.9322\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0505 - accuracy: 0.9354 - val_loss: 0.0712 - val_accuracy: 0.9153\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0484 - accuracy: 0.9422 - val_loss: 0.0698 - val_accuracy: 0.9153\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0482 - accuracy: 0.9456 - val_loss: 0.0692 - val_accuracy: 0.9153\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.9422 - val_loss: 0.0702 - val_accuracy: 0.9153\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0491 - accuracy: 0.9388 - val_loss: 0.0731 - val_accuracy: 0.8983\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0488 - accuracy: 0.9422 - val_loss: 0.0685 - val_accuracy: 0.9153\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0485 - accuracy: 0.9524 - val_loss: 0.0682 - val_accuracy: 0.9153\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0512 - accuracy: 0.9388 - val_loss: 0.0747 - val_accuracy: 0.8983\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0486 - accuracy: 0.9388 - val_loss: 0.0681 - val_accuracy: 0.9153\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0464 - accuracy: 0.9558 - val_loss: 0.0681 - val_accuracy: 0.9153\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0458 - accuracy: 0.9558 - val_loss: 0.0676 - val_accuracy: 0.9153\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0451 - accuracy: 0.9558 - val_loss: 0.0664 - val_accuracy: 0.9153\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0449 - accuracy: 0.9558 - val_loss: 0.0663 - val_accuracy: 0.9153\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0447 - accuracy: 0.9592 - val_loss: 0.0667 - val_accuracy: 0.9153\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0445 - accuracy: 0.9558 - val_loss: 0.0666 - val_accuracy: 0.9153\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0437 - accuracy: 0.9592 - val_loss: 0.0652 - val_accuracy: 0.9153\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0441 - accuracy: 0.9524 - val_loss: 0.0643 - val_accuracy: 0.9153\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0434 - accuracy: 0.9524 - val_loss: 0.0648 - val_accuracy: 0.9153\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0430 - accuracy: 0.9592 - val_loss: 0.0655 - val_accuracy: 0.9153\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9592 - val_loss: 0.0650 - val_accuracy: 0.9153\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0426 - accuracy: 0.9592 - val_loss: 0.0641 - val_accuracy: 0.9153\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.9592 - val_loss: 0.0619 - val_accuracy: 0.9153\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9524 - val_loss: 0.0606 - val_accuracy: 0.9153\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0415 - accuracy: 0.9524 - val_loss: 0.0618 - val_accuracy: 0.9153\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9592 - val_loss: 0.0635 - val_accuracy: 0.9153\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9592 - val_loss: 0.0608 - val_accuracy: 0.9153\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0404 - accuracy: 0.9558 - val_loss: 0.0605 - val_accuracy: 0.9153\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0402 - accuracy: 0.9592 - val_loss: 0.0615 - val_accuracy: 0.9153\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0399 - accuracy: 0.9592 - val_loss: 0.0600 - val_accuracy: 0.9153\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0395 - accuracy: 0.9592 - val_loss: 0.0595 - val_accuracy: 0.9153\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0410 - accuracy: 0.9524 - val_loss: 0.0578 - val_accuracy: 0.9153\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0389 - accuracy: 0.9592 - val_loss: 0.0603 - val_accuracy: 0.9153\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0390 - accuracy: 0.9592 - val_loss: 0.0587 - val_accuracy: 0.9153\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0384 - accuracy: 0.9592 - val_loss: 0.0587 - val_accuracy: 0.9153\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0382 - accuracy: 0.9592 - val_loss: 0.0581 - val_accuracy: 0.9153\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0378 - accuracy: 0.9592 - val_loss: 0.0573 - val_accuracy: 0.9153\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0378 - accuracy: 0.9558 - val_loss: 0.0562 - val_accuracy: 0.9153\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0375 - accuracy: 0.9592 - val_loss: 0.0575 - val_accuracy: 0.9322\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0375 - accuracy: 0.9558 - val_loss: 0.0552 - val_accuracy: 0.9153\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 0.9558 - val_loss: 0.0532 - val_accuracy: 0.9322\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0364 - accuracy: 0.9626 - val_loss: 0.0548 - val_accuracy: 0.9153\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0370 - accuracy: 0.9626 - val_loss: 0.0563 - val_accuracy: 0.9322\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0361 - accuracy: 0.9558 - val_loss: 0.0529 - val_accuracy: 0.9322\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0362 - accuracy: 0.9626 - val_loss: 0.0526 - val_accuracy: 0.9322\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9660 - val_loss: 0.0542 - val_accuracy: 0.9322\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9626 - val_loss: 0.0533 - val_accuracy: 0.9322\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0351 - accuracy: 0.9660 - val_loss: 0.0518 - val_accuracy: 0.9322\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0346 - accuracy: 0.9660 - val_loss: 0.0509 - val_accuracy: 0.9322\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0343 - accuracy: 0.9694 - val_loss: 0.0494 - val_accuracy: 0.9492\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0342 - accuracy: 0.9694 - val_loss: 0.0501 - val_accuracy: 0.9492\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.9694 - val_loss: 0.0499 - val_accuracy: 0.9492\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0336 - accuracy: 0.9694 - val_loss: 0.0487 - val_accuracy: 0.9492\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9694 - val_loss: 0.0481 - val_accuracy: 0.9492\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0333 - accuracy: 0.9694 - val_loss: 0.0493 - val_accuracy: 0.9492\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0329 - accuracy: 0.9694 - val_loss: 0.0479 - val_accuracy: 0.9492\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0327 - accuracy: 0.9694 - val_loss: 0.0475 - val_accuracy: 0.9492\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0325 - accuracy: 0.9694 - val_loss: 0.0463 - val_accuracy: 0.9492\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0323 - accuracy: 0.9694 - val_loss: 0.0461 - val_accuracy: 0.9492\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9694 - val_loss: 0.0459 - val_accuracy: 0.9492\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0322 - accuracy: 0.9660 - val_loss: 0.0442 - val_accuracy: 0.9492\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0320 - accuracy: 0.9660 - val_loss: 0.0484 - val_accuracy: 0.9322\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0318 - accuracy: 0.9694 - val_loss: 0.0452 - val_accuracy: 0.9492\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9728 - val_loss: 0.0403 - val_accuracy: 0.9661\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0315 - accuracy: 0.9694 - val_loss: 0.0446 - val_accuracy: 0.9492\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0308 - accuracy: 0.9694 - val_loss: 0.0434 - val_accuracy: 0.9492\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.9694 - val_loss: 0.0431 - val_accuracy: 0.9492\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0303 - accuracy: 0.9694 - val_loss: 0.0410 - val_accuracy: 0.9492\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0299 - accuracy: 0.9694 - val_loss: 0.0411 - val_accuracy: 0.9492\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 0.9694 - val_loss: 0.0411 - val_accuracy: 0.9492\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0295 - accuracy: 0.9728 - val_loss: 0.0421 - val_accuracy: 0.9492\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0294 - accuracy: 0.9728 - val_loss: 0.0403 - val_accuracy: 0.9492\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0295 - accuracy: 0.9694 - val_loss: 0.0414 - val_accuracy: 0.9492\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0287 - accuracy: 0.9728 - val_loss: 0.0389 - val_accuracy: 0.9492\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0299 - accuracy: 0.9762 - val_loss: 0.0371 - val_accuracy: 0.9661\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 0.9694 - val_loss: 0.0414 - val_accuracy: 0.9492\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9728 - val_loss: 0.0393 - val_accuracy: 0.9492\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9728 - val_loss: 0.0390 - val_accuracy: 0.9492\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9728 - val_loss: 0.0365 - val_accuracy: 0.9661\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9762 - val_loss: 0.0369 - val_accuracy: 0.9661\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0280 - accuracy: 0.9728 - val_loss: 0.0381 - val_accuracy: 0.9661\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0274 - accuracy: 0.9762 - val_loss: 0.0365 - val_accuracy: 0.9661\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0273 - accuracy: 0.9728 - val_loss: 0.0358 - val_accuracy: 0.9661\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0272 - accuracy: 0.9762 - val_loss: 0.0361 - val_accuracy: 0.9661\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9762 - val_loss: 0.0362 - val_accuracy: 0.9661\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.9728 - val_loss: 0.0349 - val_accuracy: 0.9661\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 0.9762 - val_loss: 0.0356 - val_accuracy: 0.9661\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0264 - accuracy: 0.9728 - val_loss: 0.0327 - val_accuracy: 0.9661\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0264 - accuracy: 0.9762 - val_loss: 0.0327 - val_accuracy: 0.9661\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9762 - val_loss: 0.0333 - val_accuracy: 0.9661\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9762 - val_loss: 0.0331 - val_accuracy: 0.9661\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 0.9762 - val_loss: 0.0321 - val_accuracy: 0.9661\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9762 - val_loss: 0.0318 - val_accuracy: 0.9661\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9762 - val_loss: 0.0316 - val_accuracy: 0.9661\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 0.9796 - val_loss: 0.0321 - val_accuracy: 0.9661\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9796 - val_loss: 0.0306 - val_accuracy: 0.9661\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9762 - val_loss: 0.0311 - val_accuracy: 0.9661\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 0.9762 - val_loss: 0.0317 - val_accuracy: 0.9661\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0247 - accuracy: 0.9796 - val_loss: 0.0300 - val_accuracy: 0.9661\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0247 - accuracy: 0.9796 - val_loss: 0.0322 - val_accuracy: 0.9661\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9796 - val_loss: 0.0300 - val_accuracy: 0.9661\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 0.9796 - val_loss: 0.0296 - val_accuracy: 0.9661\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0245 - accuracy: 0.9762 - val_loss: 0.0284 - val_accuracy: 0.9661\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9762 - val_loss: 0.0296 - val_accuracy: 0.9661\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0241 - accuracy: 0.9796 - val_loss: 0.0292 - val_accuracy: 0.9661\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9796 - val_loss: 0.0278 - val_accuracy: 0.9661\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0238 - accuracy: 0.9762 - val_loss: 0.0272 - val_accuracy: 0.9661\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9762 - val_loss: 0.0277 - val_accuracy: 0.9661\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0235 - accuracy: 0.9796 - val_loss: 0.0274 - val_accuracy: 0.9661\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9796 - val_loss: 0.0271 - val_accuracy: 0.9661\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9762 - val_loss: 0.0259 - val_accuracy: 0.9661\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0250 - accuracy: 0.9762 - val_loss: 0.0229 - val_accuracy: 0.9831\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 0.9728 - val_loss: 0.0257 - val_accuracy: 0.9661\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0228 - accuracy: 0.9762 - val_loss: 0.0235 - val_accuracy: 0.9831\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0229 - accuracy: 0.9796 - val_loss: 0.0236 - val_accuracy: 0.9831\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0235 - accuracy: 0.9796 - val_loss: 0.0265 - val_accuracy: 0.9661\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9796 - val_loss: 0.0233 - val_accuracy: 0.9831\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9796 - val_loss: 0.0242 - val_accuracy: 0.9661\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0225 - accuracy: 0.9762 - val_loss: 0.0259 - val_accuracy: 0.9661\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 0.9796 - val_loss: 0.0235 - val_accuracy: 0.9831\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9796 - val_loss: 0.0227 - val_accuracy: 0.9831\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0220 - accuracy: 0.9796 - val_loss: 0.0240 - val_accuracy: 0.9661\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9796 - val_loss: 0.0228 - val_accuracy: 0.9831\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0217 - accuracy: 0.9830 - val_loss: 0.0227 - val_accuracy: 0.9831\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9830 - val_loss: 0.0228 - val_accuracy: 0.9831\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9830 - val_loss: 0.0225 - val_accuracy: 0.9831\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9830 - val_loss: 0.0225 - val_accuracy: 0.9831\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 0.9796 - val_loss: 0.0211 - val_accuracy: 0.9831\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0214 - accuracy: 0.9796 - val_loss: 0.0224 - val_accuracy: 0.9831\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0213 - accuracy: 0.9830 - val_loss: 0.0226 - val_accuracy: 0.9831\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0212 - accuracy: 0.9796 - val_loss: 0.0215 - val_accuracy: 0.9831\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9796 - val_loss: 0.0206 - val_accuracy: 0.9831\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0210 - accuracy: 0.9796 - val_loss: 0.0219 - val_accuracy: 0.9831\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0209 - accuracy: 0.9830 - val_loss: 0.0221 - val_accuracy: 0.9831\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9830 - val_loss: 0.0213 - val_accuracy: 0.9831\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9830 - val_loss: 0.0215 - val_accuracy: 0.9831\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9830 - val_loss: 0.0211 - val_accuracy: 0.9831\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9830 - val_loss: 0.0214 - val_accuracy: 0.9831\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 0.9830 - val_loss: 0.0208 - val_accuracy: 0.9831\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9830 - val_loss: 0.0203 - val_accuracy: 0.9831\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9830 - val_loss: 0.0202 - val_accuracy: 0.9831\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9796 - val_loss: 0.0197 - val_accuracy: 0.9831\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0203 - accuracy: 0.9796 - val_loss: 0.0211 - val_accuracy: 0.9831\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0202 - accuracy: 0.9830 - val_loss: 0.0203 - val_accuracy: 0.9831\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0200 - accuracy: 0.9830 - val_loss: 0.0198 - val_accuracy: 0.9831\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0200 - accuracy: 0.9830 - val_loss: 0.0199 - val_accuracy: 0.9831\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9830 - val_loss: 0.0196 - val_accuracy: 0.9831\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9830 - val_loss: 0.0198 - val_accuracy: 0.9831\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0198 - accuracy: 0.9830 - val_loss: 0.0201 - val_accuracy: 0.9831\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0197 - accuracy: 0.9830 - val_loss: 0.0193 - val_accuracy: 0.9831\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0198 - accuracy: 0.9796 - val_loss: 0.0190 - val_accuracy: 0.9831\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0198 - accuracy: 0.9830 - val_loss: 0.0199 - val_accuracy: 0.9831\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9830 - val_loss: 0.0186 - val_accuracy: 0.9831\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0196 - accuracy: 0.9830 - val_loss: 0.0189 - val_accuracy: 0.9831\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9830 - val_loss: 0.0193 - val_accuracy: 0.9831\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9830 - val_loss: 0.0186 - val_accuracy: 0.9831\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9830 - val_loss: 0.0187 - val_accuracy: 0.9831\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9830 - val_loss: 0.0188 - val_accuracy: 0.9831\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9830 - val_loss: 0.0186 - val_accuracy: 0.9831\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 0.9830 - val_loss: 0.0195 - val_accuracy: 0.9831\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 0.9830 - val_loss: 0.0186 - val_accuracy: 0.9831\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0189 - accuracy: 0.9830 - val_loss: 0.0187 - val_accuracy: 0.9831\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 0.9830 - val_loss: 0.0186 - val_accuracy: 0.9831\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9830 - val_loss: 0.0179 - val_accuracy: 0.9831\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0188 - accuracy: 0.9830 - val_loss: 0.0181 - val_accuracy: 0.9831\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9830 - val_loss: 0.0175 - val_accuracy: 0.9831\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0187 - accuracy: 0.9830 - val_loss: 0.0178 - val_accuracy: 0.9831\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9830 - val_loss: 0.0175 - val_accuracy: 0.9831\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9830 - val_loss: 0.0177 - val_accuracy: 0.9831\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0185 - accuracy: 0.9830 - val_loss: 0.0172 - val_accuracy: 0.9831\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0183 - accuracy: 0.9830 - val_loss: 0.0174 - val_accuracy: 0.9831\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0181 - accuracy: 0.9830 - val_loss: 0.0170 - val_accuracy: 0.9831\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 0.9830 - val_loss: 0.0169 - val_accuracy: 0.9831\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 0.9830 - val_loss: 0.0173 - val_accuracy: 0.9831\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0180 - accuracy: 0.9830 - val_loss: 0.0169 - val_accuracy: 0.9831\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 0.9796 - val_loss: 0.0166 - val_accuracy: 0.9831\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0183 - accuracy: 0.9830 - val_loss: 0.0172 - val_accuracy: 0.9831\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0177 - accuracy: 0.9796 - val_loss: 0.0161 - val_accuracy: 0.9831\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0207 - accuracy: 0.9796 - val_loss: 0.0158 - val_accuracy: 0.9831\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0175 - accuracy: 0.9830 - val_loss: 0.0179 - val_accuracy: 0.9831\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0170 - accuracy: 0.9830 - val_loss: 0.0160 - val_accuracy: 0.9831\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0174 - accuracy: 0.9830 - val_loss: 0.0163 - val_accuracy: 0.9831\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0170 - accuracy: 0.9830 - val_loss: 0.0179 - val_accuracy: 0.9831\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0166 - accuracy: 0.9830 - val_loss: 0.0164 - val_accuracy: 0.9831\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0164 - accuracy: 0.9864 - val_loss: 0.0154 - val_accuracy: 0.9831\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0163 - accuracy: 0.9830 - val_loss: 0.0161 - val_accuracy: 0.9831\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0161 - accuracy: 0.9830 - val_loss: 0.0156 - val_accuracy: 0.9831\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0160 - accuracy: 0.9864 - val_loss: 0.0152 - val_accuracy: 0.9831\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 0.9864 - val_loss: 0.0152 - val_accuracy: 0.9831\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0158 - accuracy: 0.9864 - val_loss: 0.0145 - val_accuracy: 0.9831\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 0.9864 - val_loss: 0.0140 - val_accuracy: 0.9831\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0155 - accuracy: 0.9864 - val_loss: 0.0138 - val_accuracy: 0.9831\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0155 - accuracy: 0.9864 - val_loss: 0.0139 - val_accuracy: 0.9831\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0153 - accuracy: 0.9864 - val_loss: 0.0126 - val_accuracy: 0.9831\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0151 - accuracy: 0.9864 - val_loss: 0.0120 - val_accuracy: 0.9831\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0150 - accuracy: 0.9864 - val_loss: 0.0111 - val_accuracy: 0.9831\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0151 - accuracy: 0.9830 - val_loss: 0.0124 - val_accuracy: 0.9831\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0149 - accuracy: 0.9864 - val_loss: 0.0126 - val_accuracy: 0.9831\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0146 - accuracy: 0.9864 - val_loss: 0.0106 - val_accuracy: 0.9831\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0146 - accuracy: 0.9864 - val_loss: 0.0093 - val_accuracy: 0.9831\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0142 - accuracy: 0.9864 - val_loss: 0.0100 - val_accuracy: 0.9831\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0140 - accuracy: 0.9864 - val_loss: 0.0092 - val_accuracy: 0.9831\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0140 - accuracy: 0.9864 - val_loss: 0.0077 - val_accuracy: 0.9831\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0138 - accuracy: 0.9864 - val_loss: 0.0081 - val_accuracy: 0.9831\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 0.9864 - val_loss: 0.0070 - val_accuracy: 0.9831\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0137 - accuracy: 0.9864 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9864 - val_loss: 0.0088 - val_accuracy: 0.9831\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0134 - accuracy: 0.9864 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - accuracy: 0.9898 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - accuracy: 0.9898 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0129 - accuracy: 0.9898 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0129 - accuracy: 0.9898 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0127 - accuracy: 0.9898 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0128 - accuracy: 0.9898 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 0.9898 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0125 - accuracy: 0.9898 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0124 - accuracy: 0.9898 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0124 - accuracy: 0.9898 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0123 - accuracy: 0.9898 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0123 - accuracy: 0.9898 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0121 - accuracy: 0.9898 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0121 - accuracy: 0.9898 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 0.9898 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0120 - accuracy: 0.9898 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0118 - accuracy: 0.9898 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0119 - accuracy: 0.9898 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0118 - accuracy: 0.9898 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0119 - accuracy: 0.9898 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 0.9898 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0116 - accuracy: 0.9898 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 0.9898 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 0.9898 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 0.9898 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 0.9898 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9898 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0115 - accuracy: 0.9898 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9898 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0126 - accuracy: 0.9898 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0120 - accuracy: 0.9898 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0110 - accuracy: 0.9898 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0116 - accuracy: 0.9898 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 0.9898 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - accuracy: 0.9898 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 0.9898 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0107 - accuracy: 0.9898 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 0.9898 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0104 - accuracy: 0.9898 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.9898 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0101 - accuracy: 0.9898 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0133 - accuracy: 0.9830 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 0.9864 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0104 - accuracy: 0.9898 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9898 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0094 - accuracy: 0.9898 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - accuracy: 0.9898 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0102 - accuracy: 0.9898 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0096 - accuracy: 0.9898 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9898 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0089 - accuracy: 0.9932 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0088 - accuracy: 0.9898 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - accuracy: 0.9898 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 0.9932 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - accuracy: 0.9898 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 0.9932 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 0.9932 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9932 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9932 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0081 - accuracy: 0.9932 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0079 - accuracy: 0.9932 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0079 - accuracy: 0.9932 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0079 - accuracy: 0.9932 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0078 - accuracy: 0.9932 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0078 - accuracy: 0.9932 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0078 - accuracy: 0.9932 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 0.9932 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 0.9932 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 0.9932 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 0.9932 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0075 - accuracy: 0.9932 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0074 - accuracy: 0.9932 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0074 - accuracy: 0.9932 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 0.9932 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9932 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0074 - accuracy: 0.9932 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 0.9932 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 0.9932 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0072 - accuracy: 0.9932 - val_loss: 0.0016 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c44e86d2a40>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction\n",
        "y_predicted = model.predict(X_test)"
      ],
      "metadata": {
        "id": "VniE2RNeZUP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8788fcbe-6edc-4593-9b92-849ad60a1bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_train, y_train)"
      ],
      "metadata": {
        "id": "kE0MAknnZXU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf99e062-bcc0-4dfe-9893-eb08abb70396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9915\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.008465801365673542, 0.9914893507957458]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model score\n",
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "id": "LlLsIUP2ZXPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c849f2-ebcf-41ba-888d-68d2a4cfc042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0016222922131419182, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_final=list()\n",
        "for i in range(len(y_predicted)):\n",
        "  if(y_predicted[i]>0.5):\n",
        "    print('%.2f (expected %d)' % (1, y_test[i]))\n",
        "    y_pred_final.append(1)\n",
        "\n",
        "  else:\n",
        "        print('%.2f (expected %d)' % (0, y_test[i]))\n",
        "        y_pred_final.append(0)\n",
        "\n",
        "\n",
        "_, accuracy = model.evaluate(X_train,y_train.ravel())\n",
        "print('Training Accuracy: %.2f\\n\\n' % (accuracy*100))\n",
        "\n",
        "_, accuracy = model.evaluate(X_test,y_test)\n",
        "print('Testing Accuracy: %.2f\\n\\n' % (accuracy*100))\n",
        "print(y_pred_final)"
      ],
      "metadata": {
        "id": "p_R45VYLd0Dy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94dd211-1e25-4b79-c2fe-4d4cef308c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9915\n",
            "Training Accuracy: 99.15\n",
            "\n",
            "\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Testing Accuracy: 100.00\n",
            "\n",
            "\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print('MAE:', metrics.mean_absolute_error(y_test, y_predicted))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_predicted))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_predicted)))\n",
        "print('VarScore:',metrics.explained_variance_score(y_test,y_predicted))"
      ],
      "metadata": {
        "id": "Lg-bHC-5eMFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e9147e-4e28-451b-f892-375055045aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.024675643702937386\n",
            "MSE: 0.0016222921680821355\n",
            "RMSE: 0.04027768821670548\n",
            "VarScore: 0.9935600151919793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred_final)\n",
        "print(cm)\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "plt.savefig(\"CM_\"+model_name+'.png')\n",
        "\n"
      ],
      "metadata": {
        "id": "y5vJYhurZXNL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "9b1622e7-df21-4826-b62f-8925773bc0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[32  0]\n",
            " [ 0 27]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the roc curve for the model\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import roc_curve\n",
        "plt.figure(figsize=(30,15))\n",
        "# calculate roc curves\n",
        "\n",
        "\n",
        "# plot the roc curve for the model\n",
        "\n",
        "\n",
        "     pyplot.plot(lr_fpr[i], lr_tpr[i], marker='.',linestyle='--', color='red'), label=\"ROC curve for fold \"+str(i+1)+\" (AUC = \"+ str(lst_roc_stratified[i]) + \")\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "plt.title(\"Area under a receiver operating characteristic curve\")\n",
        "\n",
        "# show the plot\n",
        "plt.savefig(model_name+'_S_auc_split_no_'+ str(split)+'(500).png')"
      ],
      "metadata": {
        "id": "CNdGfDBALBKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4fIqqPQJvBM",
        "outputId": "c9dc43c8-6124-4c10-d618-65877c3bd739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the entire model as a `.keras` zip archive.\n",
        "model.save('my_model.keras')"
      ],
      "metadata": {
        "id": "VnAkFeFQJ65b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model('my_model.keras')\n",
        "\n",
        "# Show the model architecture\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jANw2w7yKGQc",
        "outputId": "1672abbb-8200-4e6c-cbbf-4da212fc6745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 30)                690       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                410       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2351 (9.18 KB)\n",
            "Trainable params: 2351 (9.18 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Precision,recall,f1_score,cohen_kappa_score,auc.......\n",
        "print(\"Precision,recall,f1 score,cohen kappa score,auc.....\")\n",
        "print(\" \")\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_pred_final)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test,y_pred_final)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_pred_final)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(y_test,  y_pred_final)\n",
        "print('ROC AUC: %f' % auc)\n",
        "#Cohen's kappa\n",
        "kappa=cohen_kappa_score(y_test,  y_pred_final)\n",
        "print('Cohen Kappa: %f' % kappa)\n",
        "print(\" \")"
      ],
      "metadata": {
        "id": "uvdylERBZccE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2fa41b-90ea-44ef-e83b-c5ec20527bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision,recall,f1 score,cohen kappa score,auc.....\n",
            " \n",
            "Precision: 1.000000\n",
            "Recall: 1.000000\n",
            "F1 score: 1.000000\n",
            "ROC AUC: 1.000000\n",
            "Cohen Kappa: 1.000000\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(model, open(\"model_\"+model_name+\".pkl\", \"wb\"))"
      ],
      "metadata": {
        "id": "iiwahK57eNxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4UO9KWYpjzTL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}